{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9f9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32d7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_calls = 400\n",
    "number_of_random_start = 250\n",
    "rbf_lengthscale = 0.08\n",
    "\n",
    "delta = 0.3\n",
    "\n",
    "n_jobs = -1 # Use all available processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab759380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function to maximize the surrogate model\n",
    "def objective_function(x):\n",
    "    # Predict using the surrogate model\n",
    "    y_pred, _ = surrogate_model.predict(np.array(x).reshape(1, -1), return_std=True)\n",
    "    return -y_pred[0]  # Negate to maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b627b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dimensions_around_max(X, Y):\n",
    "    max_index = np.argmax(Y)\n",
    "    input_column = X[max_index]\n",
    "    dimensions = [Real(max(0.000000, x - delta), min(0.999999, x + delta)) for x in input_column]\n",
    "    return dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e26fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dimensions_around_local_max(X, Y):\n",
    "    max_index = np.argmax(Y)\n",
    "    \n",
    "    # Identify potential local maxima\n",
    "    potential_maxima = [i for i in range(len(Y)) if Y[i] > 0.8 * Y[max_index]] \n",
    "    \n",
    "    # Choose the local maximum with X values far enough from the absolute maximum\n",
    "    def distance_from_absolute_max(i):\n",
    "        return np.max(np.abs(X[i] - X[max_index]))\n",
    "\n",
    "    local_max_index = max(potential_maxima, key=distance_from_absolute_max)\n",
    "\n",
    "    input_column = X[local_max_index]\n",
    "    dimensions = [Real(max(0.000000, x - delta), min(0.999999, x + delta)) for x in input_column]\n",
    "    return dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef980c9c",
   "metadata": {},
   "source": [
    "Week 1: random manual numbers\n",
    "\n",
    "Week 2: trying linear regression vs forrest + manual maxima\n",
    "\n",
    "Week 3: trying linear regression + change parameter + manual maxima\n",
    "\n",
    "Week 4: Current bayesian implementation\n",
    "    trying rbf kernel\n",
    "    \n",
    "week 5:\n",
    "    trying matern kernel\n",
    "    \n",
    "week 6:\n",
    "    trying sum kernel\n",
    "    \n",
    "week 7: Trying the most succesfull week (rbf) so far, with additional data, on the entirety of 0 to 1\n",
    "    number_of_calls = 150\n",
    "    number_of_random_start = 75\n",
    "    rbf_lengthscale = 0.08\n",
    "    \n",
    "week 8: Only predicting around the highest values for each set instead of 0.0 to 9.999\n",
    "\n",
    "Week 9: Same as week 8 with different RBF lengthscale\n",
    "\n",
    "Week 10: Trying to look away from the current maximum as we could potentially be stuck in a local max. Finding maximum far away from the max and look around it.\n",
    "\n",
    "Week 11: For the final submission, take the best of the above and parallelize the code to run on a better machine with a much higher number of calls and random starts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4c1d3",
   "metadata": {},
   "source": [
    "***\n",
    "## Function 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70b0e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_X = np.load('initial_data/function_1/initial_inputs.npy')\n",
    "f1_Y = np.load('initial_data/function_1/initial_outputs.npy')\n",
    "\n",
    "new_f1_X = np.load('initial_data2/function_1/initial_inputs.npy')\n",
    "new_f1_Y = np.load('initial_data2/function_1/initial_outputs.npy')\n",
    "\n",
    "# Concatenate the new data with the original data\n",
    "f1_X = np.concatenate((f1_X, new_f1_X), axis=0)\n",
    "f1_Y = np.concatenate((f1_Y, new_f1_Y), axis=0)\n",
    "\n",
    "#Week 1\n",
    "f1_X = np.vstack((f1_X, np.array([0.83, 0.29])))\n",
    "f1_Y = np.append(f1_Y, -3.2860097425164E-109)\n",
    "#Week 2\n",
    "f1_X = np.vstack((f1_X, np.array([0.619903,0.245888])))\n",
    "f1_Y = np.append(f1_Y, -1.01694853412876E-50)\n",
    "#Week 3\n",
    "f1_X = np.vstack((f1_X, np.array([0.775021,0.265669])))\n",
    "f1_Y = np.append(f1_Y, -1.24778222636534E-106)\n",
    "#Week 4\n",
    "f1_X = np.vstack((f1_X, np.array([0.549448,0.600462])))\n",
    "f1_Y = np.append(f1_Y, -0.0000110332053603618)\n",
    "#Week 5\n",
    "f1_X = np.vstack((f1_X, np.array([0.785116,0.729309])))\n",
    "f1_Y = np.append(f1_Y, -1.02E-24)\n",
    "#Week 6\n",
    "f1_X = np.vstack((f1_X, np.array([0.743678,0.764168])))\n",
    "f1_Y = np.append(f1_Y, -1.41453726950899E-23)\n",
    "#Week 7\n",
    "f1_X = np.vstack((f1_X, np.array([0.597106,0.614121])))\n",
    "f1_Y = np.append(f1_Y, 0.0762719854223018)\n",
    "#Week 8\n",
    "f1_X = np.vstack((f1_X, np.array([0.614246,0.615296])))\n",
    "f1_Y = np.append(f1_Y, 0.790547512875297)\n",
    "#Week 9\n",
    "f1_X = np.vstack((f1_X, np.array([0.677835,0.593512])))\n",
    "f1_Y = np.append(f1_Y, -0.0003792444576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985d4e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 10441.67767572403 seconds\n",
      "Input: [0.6255801946376838, 0.6160773268517411] --> Output: 1.0793423239757796\n",
      "0.625580-0.616077\n"
     ]
    }
   ],
   "source": [
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "surrogate_model = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=kernel))\n",
    "\n",
    "#kernel = Matern(length_scale=1.0, nu=2.5)\n",
    "#surrogate_model = GaussianProcessRegressor(kernel=kernel)\n",
    "#surrogate_model = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=kernel))\n",
    "\n",
    "surrogate_model.fit(f1_X, f1_Y)\n",
    "\n",
    "dimensions = find_dimensions_around_max(f1_X, f1_Y)\n",
    "#dimensions = [\n",
    "#    Real(0.000000, 0.999999, name='x1'),\n",
    "#    Real(0.000000, 0.999999, name='x2')\n",
    "#]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    dimensions=dimensions,\n",
    "    n_calls=number_of_calls, \n",
    "    n_random_starts=number_of_random_start,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "print(\"Input: {} --> Output: {}\".format(result.x,-result.fun))\n",
    "formatted_x1 = '-'.join([f'{x:.6f}' for x in result.x])\n",
    "print(formatted_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647ff77",
   "metadata": {},
   "source": [
    "***\n",
    "## Function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d68ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_X = np.load('initial_data/function_2/initial_inputs.npy')\n",
    "f2_Y = np.load('initial_data/function_2/initial_outputs.npy')\n",
    "\n",
    "new_f2_X = np.load('initial_data2/function_2/initial_inputs.npy')\n",
    "new_f2_Y = np.load('initial_data2/function_2/initial_outputs.npy')\n",
    "\n",
    "# Concatenate the new data with the original data\n",
    "f2_X = np.concatenate((f2_X, new_f2_X), axis=0)\n",
    "f2_Y = np.concatenate((f2_Y, new_f2_Y), axis=0)\n",
    "\n",
    "#Week 1\n",
    "f2_X = np.vstack((f2_X, np.array([0.71, 0.99])))\n",
    "f2_Y = np.append(f2_Y, 0.7093867276)\n",
    "#Week 2\n",
    "f2_X = np.vstack((f2_X, np.array([0.87779,0.99])))\n",
    "f2_Y = np.append(f2_Y, -0.02792512905)\n",
    "#Week 3\n",
    "f2_X = np.vstack((f2_X, np.array([0.877791,0.99])))\n",
    "f2_Y = np.append(f2_Y, 0.07256572223)\n",
    "#Week 4\n",
    "f2_X = np.vstack((f2_X, np.array([0.883564,0.99])))\n",
    "f2_Y = np.append(f2_Y, 0.009198636598)\n",
    "#Week 5\n",
    "f2_X = np.vstack((f2_X, np.array([0.913759,0.989874])))\n",
    "f2_Y = np.append(f2_Y, -0.1076669936)\n",
    "#Week 6\n",
    "f2_X = np.vstack((f2_X, np.array([0.974913,0.999999])))\n",
    "f2_Y = np.append(f2_Y, -0.0396112707405163)\n",
    "#Week 7\n",
    "f2_X = np.vstack((f2_X, np.array([0.931841,0.990063])))\n",
    "f2_Y = np.append(f2_Y, 0.01882726689)\n",
    "#Week 8\n",
    "f2_X = np.vstack((f2_X, np.array([0.709824,0.986201])))\n",
    "f2_Y = np.append(f2_Y, 0.6477917306)\n",
    "#Week 9\n",
    "f2_X = np.vstack((f2_X, np.array([0.64625,0.999999])))\n",
    "f2_Y = np.append(f2_Y, 0.3140346957)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7672ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.9225606999716331, 0.9873649261924347] --> Output: 185.50617078349933\n",
      "0.922561-0.987365\n"
     ]
    }
   ],
   "source": [
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "surrogate_model = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=kernel))\n",
    "\n",
    "surrogate_model.fit(f2_X, f2_Y)\n",
    "\n",
    "dimensions = find_dimensions_around_max(f2_X, f2_Y)\n",
    "\n",
    "#dimensions = [\n",
    "#    Real(0.000000, 0.999999, name='x1'),\n",
    "#    Real(0.000000, 0.999999, name='x2')\n",
    "#]\n",
    "\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    dimensions=dimensions,\n",
    "    n_calls=number_of_calls, \n",
    "    verbose=False,\n",
    "    n_random_starts=number_of_random_start,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "\n",
    "print(\"Input: {} --> Output: {}\".format(result.x,-result.fun))\n",
    "formatted_x2 = '-'.join([f'{x:.6f}' for x in result.x])\n",
    "print(formatted_x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9752da9",
   "metadata": {},
   "source": [
    "***\n",
    "## Function 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd72818",
   "metadata": {},
   "outputs": [],
   "source": [
    "f3_X = np.load('initial_data/function_3/initial_inputs.npy')\n",
    "f3_Y = np.load('initial_data/function_3/initial_outputs.npy')\n",
    "\n",
    "new_f3_X = np.load('initial_data2/function_3/initial_inputs.npy')\n",
    "new_f3_Y = np.load('initial_data2/function_3/initial_outputs.npy')\n",
    "\n",
    "# Concatenate the new data with the original data\n",
    "f3_X = np.concatenate((f3_X, new_f3_X), axis=0)\n",
    "f3_Y = np.concatenate((f3_Y, new_f3_Y), axis=0)\n",
    "\n",
    "#Week 1\n",
    "f3_X = np.vstack((f3_X, np.array([0.54,0.65,0.2])))\n",
    "f3_Y = np.append(f3_Y, -0.1309050532)\n",
    "#Week 2\n",
    "f3_X = np.vstack((f3_X, np.array([0.718668,0.999945,0.272151])))\n",
    "f3_Y = np.append(f3_Y, -0.1413686626)\n",
    "#Week 3\n",
    "f3_X = np.vstack((f3_X, np.array([0.596189,0.614615,0.214115])))\n",
    "f3_Y = np.append(f3_Y, -0.11486006842883)\n",
    "#Week 4\n",
    "f3_X = np.vstack((f3_X, np.array([0.124154,0.849855,0.738203])))\n",
    "f3_Y = np.append(f3_Y, -0.142476683810238)\n",
    "#Week 5\n",
    "f3_X = np.vstack((f3_X, np.array([0.91942,0.037235,0.806635])))\n",
    "f3_Y = np.append(f3_Y, -0.1409064565)\n",
    "#Week 6\n",
    "f3_X = np.vstack((f3_X, np.array([[0.56002,0.999999,0.999999]])))\n",
    "f3_Y = np.append(f3_Y, -0.4871510136)\n",
    "#Week 7\n",
    "f3_X = np.vstack((f3_X, np.array([0.999999,0.729995,0.00984 ])))\n",
    "f3_Y = np.append(f3_Y, -0.09678844518)\n",
    "#Week 8\n",
    "f3_X = np.vstack((f3_X, np.array([[0.475798,0.222853,0.434177]])))\n",
    "f3_Y = np.append(f3_Y, -0.05597062399)\n",
    "#Week 9\n",
    "# Same input ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9a01ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.7836074381413918, 0.022852844175113518, 0.43287507074837694] --> Output: -1.3704923619454252e-52\n",
      "0.783607-0.022853-0.432875\n"
     ]
    }
   ],
   "source": [
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "surrogate_model = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=kernel))\n",
    "\n",
    "surrogate_model.fit(f3_X, f3_Y)\n",
    "\n",
    "dimensions = find_dimensions_around_max(f3_X, f3_Y)\n",
    "\n",
    "#dimensions = [\n",
    "#    Real(0.000000, 0.999999, name='x1'), \n",
    "#    Real(0.000000, 0.999999, name='x2'),\n",
    "#    Real(0.000000, 0.999999, name='x3') \n",
    "#]\n",
    "\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    dimensions=dimensions,\n",
    "    n_calls=number_of_calls,\n",
    "    verbose=False,\n",
    "    n_random_starts=number_of_random_start,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "\n",
    "print(\"Input: {} --> Output: {}\".format(result.x,-result.fun))\n",
    "formatted_x3 = '-'.join([f'{x:.6f}' for x in result.x])\n",
    "print(formatted_x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbdc553",
   "metadata": {},
   "source": [
    "***\n",
    "## Function 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "177e75f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f4_X = np.load('initial_data/function_4/initial_inputs.npy')\n",
    "f4_Y = np.load('initial_data/function_4/initial_outputs.npy')\n",
    "\n",
    "new_f4_X = np.load('initial_data2/function_4/initial_inputs.npy')\n",
    "new_f4_Y = np.load('initial_data2/function_4/initial_outputs.npy')\n",
    "\n",
    "# Concatenate the new data with the original data\n",
    "f4_X = np.concatenate((f4_X, new_f4_X), axis=0)\n",
    "f4_Y = np.concatenate((f4_Y, new_f4_Y), axis=0)\n",
    "\n",
    "#Week 1\n",
    "f4_X = np.vstack((f4_X, np.array([0.12,0.101,0.36,0.24])))\n",
    "f4_Y = np.append(f4_Y, -10.2679334484568)\n",
    "#Week 2\n",
    "f4_X = np.vstack((f4_X, np.array([0.401067,0.465459,0.990034,0.337921])))\n",
    "f4_Y = np.append(f4_Y, -17.45206644)\n",
    "#Week 3\n",
    "f4_X = np.vstack((f4_X, np.array([0.398924,0.448872,0.912348,0.328706])))\n",
    "f4_Y = np.append(f4_Y, -14.27743893)\n",
    "#Week 4\n",
    "f4_X = np.vstack((f4_X, np.array([0.961534,0.902131,0.835173,0.600658])))\n",
    "f4_Y = np.append(f4_Y, -33.189198584856)\n",
    "#Week 5\n",
    "f4_X = np.vstack((f4_X, np.array([0.643583,0.999999,0.999999,0.033833])))\n",
    "f4_Y = np.append(f4_Y, -37.2036304)\n",
    "#Week 6\n",
    "f4_X = np.vstack((f4_X, np.array([0.999999,0.048693,0.059318,0.293845])))\n",
    "f4_Y = np.append(f4_Y, -25.7829225)\n",
    "#Week 7\n",
    "f4_X = np.vstack((f4_X, np.array([0.022451,0.9303,0.987882,0.003071])))\n",
    "f4_Y = np.append(f4_Y, -36.95741928)\n",
    "#Week 8\n",
    "f4_X = np.vstack((f4_X, np.array([0.667426,0.339794,0.519347,0.168577])))\n",
    "f4_Y = np.append(f4_Y, -8.40414859)\n",
    "#Week 9\n",
    "f4_X = np.vstack((f4_X, np.array([0.477766,0.328772,0.525826,0.349007])))\n",
    "f4_Y = np.append(f4_Y, -2.353407563)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b03e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.32383136624676534, 0.4131185462839491, 0.6397357884770847, 0.5878370395471002] --> Output: -7.209599189149367e-44\n",
      "0.323831-0.413119-0.639736-0.587837\n"
     ]
    }
   ],
   "source": [
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "surrogate_model = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=kernel))\n",
    "\n",
    "surrogate_model.fit(f4_X, f4_Y)\n",
    "\n",
    "dimensions = find_dimensions_around_max(f4_X, f4_Y)\n",
    "\n",
    "#dimensions = [\n",
    "#    Real(0.000000, 0.999999, name='x1'),\n",
    "#    Real(0.000000, 0.999999, name='x2'),\n",
    "#    Real(0.000000, 0.999999, name='x3'),\n",
    "#    Real(0.000000, 0.999999, name='x4')\n",
    "#]\n",
    "\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    dimensions=dimensions,\n",
    "    n_calls=number_of_calls, \n",
    "    verbose=False,\n",
    "    n_random_starts=number_of_random_start,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "\n",
    "print(\"Input: {} --> Output: {}\".format(result.x,-result.fun))\n",
    "formatted_x4 = '-'.join([f'{x:.6f}' for x in result.x])\n",
    "print(formatted_x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85722016",
   "metadata": {},
   "source": [
    "***\n",
    "## Function 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d0c56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f5_X = np.load('initial_data/function_5/initial_inputs.npy')\n",
    "f5_Y = np.load('initial_data/function_5/initial_outputs.npy')\n",
    "\n",
    "new_f5_X = np.load('initial_data2/function_5/initial_inputs.npy')\n",
    "new_f5_Y = np.load('initial_data2/function_5/initial_outputs.npy')\n",
    "\n",
    "# Concatenate the new data with the original data\n",
    "f5_X = np.concatenate((f5_X, new_f5_X), axis=0)\n",
    "f5_Y = np.concatenate((f5_Y, new_f5_Y), axis=0)\n",
    "\n",
    "#Week 1\n",
    "f5_X = np.vstack((f5_X, np.array([0.23,0.9,0.8,0.9])))\n",
    "f5_Y = np.append(f5_Y, 1113.607380032)\n",
    "#Week 2\n",
    "f5_X = np.vstack((f5_X, np.array([0.119879,0.9,0.879484,0.957644])))\n",
    "f5_Y = np.append(f5_Y, 1854.055026)\n",
    "#Week 3\n",
    "#Same input\n",
    "#Week 4\n",
    "f5_X = np.vstack((f5_X, np.array([0.781781,0.621022,0.901272,0.827289])))\n",
    "f5_Y = np.append(f5_Y, 1000.424187)\n",
    "#Week 5\n",
    "f5_X = np.vstack((f5_X, np.array([0.510993,0.818001,0.7287,0.112178])))\n",
    "f5_Y = np.append(f5_Y, 79.72680503)\n",
    "#Week 6\n",
    "f5_X = np.vstack((f5_X, np.array([0.221762,0.875412,0.838642,0.894668])))\n",
    "f5_Y = np.append(f5_Y, 1115.020253)\n",
    "#Week 7\n",
    "f5_X = np.vstack((f5_X, np.array([0.439012,0.774128,0.377988,0.933526])))\n",
    "f5_Y = np.append(f5_Y, 355.3160089)\n",
    "#Week 8\n",
    "f5_X = np.vstack((f5_X, np.array([0.30559,0.93653,0.95385,0.883531])))\n",
    "f5_Y = np.append(f5_Y, 2136.283243)\n",
    "#Week 9\n",
    "f5_X = np.vstack((f5_X, np.array([0.298797,0.930974,0.948793,0.883932])))\n",
    "f5_Y = np.append(f5_Y, 2052.197033)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7be6954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.11989137917271951, 0.8625948936079095, 0.654016918680242, 0.8497836986528191] --> Output: 386.4463909784588\n",
      "0.119891-0.862595-0.654017-0.849784\n"
     ]
    }
   ],
   "source": [
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "surrogate_model = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=kernel))\n",
    "\n",
    "surrogate_model.fit(f5_X, f5_Y)\n",
    "\n",
    "dimensions = find_dimensions_around_max(f5_X, f5_Y)\n",
    "\n",
    "#dimensions = [\n",
    "#    Real(0.000000, 0.999999, name='x1'),\n",
    "#    Real(0.000000, 0.999999, name='x2'),\n",
    "#    Real(0.000000, 0.999999, name='x3'),\n",
    "#    Real(0.000000, 0.999999, name='x4')\n",
    "#]\n",
    "\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    dimensions=dimensions,\n",
    "    n_calls=number_of_calls, \n",
    "    verbose=False,\n",
    "    n_random_starts=number_of_random_start,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "\n",
    "print(\"Input: {} --> Output: {}\".format(result.x,-result.fun))\n",
    "formatted_x5 = '-'.join([f'{x:.6f}' for x in result.x])\n",
    "print(formatted_x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4cd2a2",
   "metadata": {},
   "source": [
    "***\n",
    "## Function 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3633bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f6_X = np.load('initial_data/function_6/initial_inputs.npy')\n",
    "f6_Y = np.load('initial_data/function_6/initial_outputs.npy')\n",
    "\n",
    "new_f6_X = np.load('initial_data2/function_6/initial_inputs.npy')\n",
    "new_f6_Y = np.load('initial_data2/function_6/initial_outputs.npy')\n",
    "\n",
    "# Concatenate the new data with the original data\n",
    "f6_X = np.concatenate((f6_X, new_f6_X), axis=0)\n",
    "f6_Y = np.concatenate((f6_Y, new_f6_Y), axis=0)\n",
    "\n",
    "#Week 1\n",
    "f6_X = np.vstack((f6_X, np.array([0.71,0.16,0.75,0.67,0.09])))\n",
    "f6_Y = np.append(f6_Y, -0.7309860846)\n",
    "#Week 2\n",
    "f6_X = np.vstack((f6_X, np.array([0.237921,0.191643,0.308479,0.169956,0.1230565])))\n",
    "f6_Y = np.append(f6_Y, -1.345672776)\n",
    "#Week 3\n",
    "f6_X = np.vstack((f6_X, np.array([0.291906,0.224345,0.332472,0.174037,0.1414308])))\n",
    "f6_Y = np.append(f6_Y, -1.33008597)\n",
    "#Week 4\n",
    "f6_X = np.vstack((f6_X, np.array([0.087971,0.967504,0.160638,0.054875,0.927092])))\n",
    "f6_Y = np.append(f6_Y, -2.894154801)\n",
    "#Week 5\n",
    "f6_X = np.vstack((f6_X, np.array([0.041704,0.955936,0.122085,0.061743,0.014749])))\n",
    "f6_Y = np.append(f6_Y, -2.329042984)\n",
    "#Week 6\n",
    "f6_X = np.vstack((f6_X, np.array([0.819207,0.121557,0.033515,0.000000,0.999999])))\n",
    "f6_Y = np.append(f6_Y, -2.917421483)\n",
    "#Week 7\n",
    "f6_X = np.vstack((f6_X, np.array([0.810012,0.181364,0.961092,0.452903,0.954819])))\n",
    "f6_Y = np.append(f6_Y, -1.966653483)\n",
    "#Week 8\n",
    "f6_X = np.vstack((f6_X, np.array([0.810125,0.054693,0.632552,0.603922,0.061692])))\n",
    "f6_Y = np.append(f6_Y, -0.880088081054918)\n",
    "#Week 9\n",
    "f6_X = np.vstack((f6_X, np.array([0.828186,0.254693,0.632552,0.793997,0.156401])))\n",
    "f6_Y = np.append(f6_Y, -0.534795741)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "143f66ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.5952377402374274, 0.5208532556978974, 0.8813661264548225, 0.8861377712223617, 0.43024189463684104] --> Output: -6.861047891416782e-86\n",
      "0.595238-0.520853-0.881366-0.886138-0.430242\n"
     ]
    }
   ],
   "source": [
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "surrogate_model = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=kernel))\n",
    "\n",
    "surrogate_model.fit(f6_X, f6_Y)\n",
    "\n",
    "dimensions = find_dimensions_around_max(f6_X, f6_Y)\n",
    "\n",
    "#dimensions = [\n",
    "#    Real(0.000000, 0.999999, name='x1'),\n",
    "#    Real(0.000000, 0.999999, name='x2'),\n",
    "#    Real(0.000000, 0.999999, name='x3'),\n",
    "#    Real(0.000000, 0.999999, name='x4'),\n",
    "#    Real(0.000000, 0.999999, name='x5')\n",
    "#]\n",
    "\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    dimensions=dimensions,\n",
    "    n_calls=number_of_calls, \n",
    "    verbose=False,\n",
    "    n_random_starts=number_of_random_start,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "\n",
    "print(\"Input: {} --> Output: {}\".format(result.x,-result.fun))\n",
    "formatted_x6 = '-'.join([f'{x:.6f}' for x in result.x])\n",
    "print(formatted_x6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0f998",
   "metadata": {},
   "source": [
    "***\n",
    "## Function 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f6c44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f7_X = np.load('initial_data/function_7/initial_inputs.npy')\n",
    "f7_Y = np.load('initial_data/function_7/initial_outputs.npy')\n",
    "\n",
    "new_f7_X = np.load('initial_data2/function_7/initial_inputs.npy')\n",
    "new_f7_Y = np.load('initial_data2/function_7/initial_outputs.npy')\n",
    "\n",
    "# Concatenate the new data with the original data\n",
    "f7_X = np.concatenate((f7_X, new_f7_X), axis=0)\n",
    "f7_Y = np.concatenate((f7_Y, new_f7_Y), axis=0)\n",
    "\n",
    "#Week 1\n",
    "f7_X = np.vstack((f7_X, np.array([0.25,0.33,0.85,0.83,0.2,0.75])))\n",
    "f7_Y = np.append(f7_Y, 0.50227388554458)\n",
    "#Week 2\n",
    "f7_X = np.vstack((f7_X, np.array([0.057896,0.924694,0.924571,0.073659,0.014944,0.951014])))\n",
    "f7_Y = np.append(f7_Y, 0.0850275940993777)\n",
    "#Week 3\n",
    "f7_X = np.vstack((f7_X, np.array([0.067896,0.824694,0.724571,0.063659,0.034944,0.851014])))\n",
    "f7_Y = np.append(f7_Y, 0.218179252964693)\n",
    "#Week 4\n",
    "f7_X = np.vstack((f7_X, np.array([0.822203,0.905431,0.608675,0.131364,0.711093,0.392675])))\n",
    "f7_Y = np.append(f7_Y, 0.008208888021)\n",
    "#Week 5\n",
    "f7_X = np.vstack((f7_X, np.array([0.920947,0.488113,0.196897,0.978698,0.051959,0.620322])))\n",
    "f7_Y = np.append(f7_Y, 0.001484417237)\n",
    "#Week 6\n",
    "f7_X = np.vstack((f7_X, np.array([0.287303,0.314722,0.926001,0.82834,0.146134,0.740828])))\n",
    "f7_Y = np.append(f7_Y, 0.4076582295)\n",
    "#Week 7\n",
    "f7_X = np.vstack((f7_X, np.array([0.245841,0.958549,0.260444,0.898014,0.493964,0.432611])))\n",
    "f7_Y = np.append(f7_Y, 0.08020004155)\n",
    "#Week 8\n",
    "f7_X = np.vstack((f7_X, np.array([0.191129,0.252443,0.391144,0.229153,0.363772,0.861907])))\n",
    "f7_Y = np.append(f7_Y, 2.11378971012324)\n",
    "#Week 9\n",
    "f7_X = np.vstack((f7_X, np.array([0.191251,0.25412,0.390648,0.233326,0.362611,0.862228])))\n",
    "f7_Y = np.append(f7_Y, 2.120640397)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba99fc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.25827770422382823, 0.19498208768729175, 0.37756943444661667, 0.26768698477669683, 0.3204322419562342, 0.8389904491456184] --> Output: 2.6344275658812322e-05\n",
      "0.258278-0.194982-0.377569-0.267687-0.320432-0.838990\n"
     ]
    }
   ],
   "source": [
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "surrogate_model = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=kernel))\n",
    "\n",
    "surrogate_model.fit(f7_X, f7_Y)\n",
    "\n",
    "dimensions = find_dimensions_around_max(f7_X, f7_Y)\n",
    "\n",
    "#dimensions = [\n",
    "#    Real(0.000000, 0.999999, name='x1'),\n",
    "#    Real(0.000000, 0.999999, name='x2'),\n",
    "#    Real(0.000000, 0.999999, name='x3'),\n",
    "#    Real(0.000000, 0.999999, name='x4'),\n",
    "#    Real(0.000000, 0.999999, name='x5'),\n",
    "#    Real(0.000000, 0.999999, name='x6')\n",
    "#]\n",
    "\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    dimensions=dimensions,\n",
    "    n_calls=number_of_calls, \n",
    "    verbose=False,\n",
    "    n_random_starts=number_of_random_start,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "\n",
    "print(\"Input: {} --> Output: {}\".format(result.x,-result.fun))\n",
    "formatted_x7 = '-'.join([f'{x:.6f}' for x in result.x])\n",
    "print(formatted_x7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755720f",
   "metadata": {},
   "source": [
    "***\n",
    "## Function 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "933ca44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f8_X = np.load('initial_data/function_8/initial_inputs.npy')\n",
    "f8_Y = np.load('initial_data/function_8/initial_outputs.npy')\n",
    "\n",
    "new_f8_X = np.load('initial_data2/function_8/initial_inputs.npy')\n",
    "new_f8_Y = np.load('initial_data2/function_8/initial_outputs.npy')\n",
    "\n",
    "# Concatenate the new data with the original data\n",
    "f8_X = np.concatenate((f8_X, new_f8_X), axis=0)\n",
    "f8_Y = np.concatenate((f8_Y, new_f8_Y), axis=0)\n",
    "\n",
    "#Week 1\n",
    "f8_X = np.vstack((f8_X, np.array([0.2,0.4,0.235,0.625,0.12,0.21,0.38,0.35])))\n",
    "f8_Y = np.append(f8_Y, 9.27245)\n",
    "#Week 2\n",
    "f8_X = np.vstack((f8_X, np.array([0.009077,0.003419,0.022929,0.009043,0.009649,0.990244,0.035909,0.988755])))\n",
    "f8_Y = np.append(f8_Y, 9.286087265)\n",
    "#Week 3\n",
    "#Same input\n",
    "#Week 4\n",
    "f8_X = np.vstack((f8_X, np.array([0.092456,0.271979,0.044189,0.249986,0.53335,0.540113,0.19916,0.544261])))\n",
    "f8_Y = np.append(f8_Y, 9.915447257)\n",
    "#Week 5\n",
    "f8_X = np.vstack((f8_X, np.array([0.759009,0.486382,0.18137,0.476835,0.742339,0.499103,0.721871,0.420298])))\n",
    "f8_Y = np.append(f8_Y, 8.353932516)\n",
    "#Week 6\n",
    "f8_X = np.vstack((f8_X, np.array([0.382459,0.730594,0.947017,0.031305,0.500582,0.735707,0.691031,0.037992])))\n",
    "f8_Y = np.append(f8_Y, 6.872514052)\n",
    "#Week 7\n",
    "f8_X = np.vstack((f8_X, np.array([0.126204,0.631699,0.715524,0.975715,0.889768,0.526422,0.7435,0.64778])))\n",
    "f8_Y = np.append(f8_Y, 7.460532387)\n",
    "#Week 8\n",
    "f8_X = np.vstack((f8_X, np.array([0.100398,0.273608,0.045201,0.252195,0.539865,0.547434,0.220625,0.544195])))\n",
    "f8_Y = np.append(f8_Y, 9.915457022)\n",
    "#Week 9\n",
    "f8_X = np.vstack((f8_X, np.array([0.095536,0.278087,0.06115,0.257399,0.512098,0.521656,0.193101,0.53147 ])))\n",
    "f8_Y = np.append(f8_Y, 9.915320762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d0dd2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0.012866824482350504, 0.3425759187623957, 0.03483457844239992, 0.19382159279286487, 0.47985148974167624, 0.5222622190565103, 0.22928933591860512, 0.45902693440390807] --> Output: 3.1291063429273053e-09\n",
      "0.012867-0.342576-0.034835-0.193822-0.479851-0.522262-0.229289-0.459027\n"
     ]
    }
   ],
   "source": [
    "kernel = RBF(length_scale=rbf_lengthscale, length_scale_bounds='fixed')\n",
    "surrogate_model = make_pipeline(StandardScaler(), GaussianProcessRegressor(kernel=kernel))\n",
    "\n",
    "surrogate_model.fit(f8_X, f8_Y)\n",
    "\n",
    "dimensions = find_dimensions_around_max(f8_X, f8_Y)\n",
    "\n",
    "#dimensions = [\n",
    "#    Real(0.000000, 0.999999, name='x1'),\n",
    "#    Real(0.000000, 0.999999, name='x2'),\n",
    "#    Real(0.000000, 0.999999, name='x3'),\n",
    "#    Real(0.000000, 0.999999, name='x4'),\n",
    "#    Real(0.000000, 0.999999, name='x5'),\n",
    "#    Real(0.000000, 0.999999, name='x6'),\n",
    "#    Real(0.000000, 0.999999, name='x7'),\n",
    "#    Real(0.000000, 0.999999, name='x8')\n",
    "#]\n",
    "\n",
    "result = gp_minimize(\n",
    "    objective_function,\n",
    "    dimensions=dimensions,\n",
    "    n_calls=number_of_calls, \n",
    "    verbose=False,\n",
    "    n_random_starts=number_of_random_start,\n",
    "    n_jobs=n_jobs,\n",
    ")\n",
    "\n",
    "print(\"Input: {} --> Output: {}\".format(result.x,-result.fun))\n",
    "formatted_x8 = '-'.join([f'{x:.6f}' for x in result.x])\n",
    "print(formatted_x8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
